{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание победителя в online игре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В работе используется задача предсказания победителя в онлайн-игре DOTA 2 https://inclass.kaggle.com/c/dota-2-win-probability-prediction. Согласно инструкциям курса необходимо построить модели Gradient Boosting и Logistic Regression на исходных признаках, а так же с добавлением мешка героев.\n",
    "\n",
    "Полученные оценки на kaggle:\n",
    "1. Градиентный бустинг на исходных признаках с параметрами n_estimators=750, learning_rate=0.1, max_depth=3 дает точность 0.73150 (место 736 из 813), что лучше, чем benchmark для градиентного бустинига, равный 0.72111.\n",
    "\n",
    "2. Логистическая регрессия на исходных признаках с \"мешком героев\" дает результат 0.75489 (место 624 из 813)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек и импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "data = pd.read_csv('./data/features.csv', index_col='match_id')\n",
    "test = pd.read_csv('./data/features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ознакомление с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>match_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>1.430199e+09</td>\n",
       "      <td>1.430220e+09</td>\n",
       "      <td>1.430227e+09</td>\n",
       "      <td>1.430264e+09</td>\n",
       "      <td>1.430282e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lobby_type</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_hero</th>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_level</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_xp</th>\n",
       "      <td>2.098000e+03</td>\n",
       "      <td>1.188000e+03</td>\n",
       "      <td>1.319000e+03</td>\n",
       "      <td>1.779000e+03</td>\n",
       "      <td>1.431000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_gold</th>\n",
       "      <td>1.489000e+03</td>\n",
       "      <td>1.033000e+03</td>\n",
       "      <td>1.270000e+03</td>\n",
       "      <td>1.056000e+03</td>\n",
       "      <td>1.090000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_lh</th>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_kills</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_deaths</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_items</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_hero</th>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_level</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_xp</th>\n",
       "      <td>8.420000e+02</td>\n",
       "      <td>1.596000e+03</td>\n",
       "      <td>1.314000e+03</td>\n",
       "      <td>5.390000e+02</td>\n",
       "      <td>6.290000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_gold</th>\n",
       "      <td>9.910000e+02</td>\n",
       "      <td>9.930000e+02</td>\n",
       "      <td>7.750000e+02</td>\n",
       "      <td>5.390000e+02</td>\n",
       "      <td>5.520000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_lh</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_kills</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_deaths</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_items</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3_hero</th>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3_level</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_flying_courier_time</th>\n",
       "      <td>2.440000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.810000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_tpscroll_count</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_boots_count</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_ward_observer_count</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>-2.000000e+01</td>\n",
       "      <td>-3.900000e+01</td>\n",
       "      <td>-3.000000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <td>1.030000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>1.240000e+02</td>\n",
       "      <td>1.820000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_courier_time</th>\n",
       "      <td>-8.400000e+01</td>\n",
       "      <td>-8.400000e+01</td>\n",
       "      <td>-7.700000e+01</td>\n",
       "      <td>-8.000000e+01</td>\n",
       "      <td>-8.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <td>2.210000e+02</td>\n",
       "      <td>1.950000e+02</td>\n",
       "      <td>2.210000e+02</td>\n",
       "      <td>1.840000e+02</td>\n",
       "      <td>2.250000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_boots_count</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <td>-5.200000e+01</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>-1.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>2.874000e+03</td>\n",
       "      <td>2.463000e+03</td>\n",
       "      <td>2.130000e+03</td>\n",
       "      <td>1.459000e+03</td>\n",
       "      <td>2.449000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiant_win</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <td>1.796000e+03</td>\n",
       "      <td>1.974000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tower_status_dire</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.830000e+03</td>\n",
       "      <td>2.047000e+03</td>\n",
       "      <td>1.974000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <td>5.100000e+01</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barracks_status_dire</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>6.300000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "match_id                                0             1             2             3             4\n",
       "start_time                   1.430199e+09  1.430220e+09  1.430227e+09  1.430264e+09  1.430282e+09\n",
       "lobby_type                   7.000000e+00  0.000000e+00  7.000000e+00  1.000000e+00  7.000000e+00\n",
       "r1_hero                      1.100000e+01  4.200000e+01  3.300000e+01  2.900000e+01  1.300000e+01\n",
       "r1_level                     5.000000e+00  4.000000e+00  4.000000e+00  4.000000e+00  4.000000e+00\n",
       "r1_xp                        2.098000e+03  1.188000e+03  1.319000e+03  1.779000e+03  1.431000e+03\n",
       "r1_gold                      1.489000e+03  1.033000e+03  1.270000e+03  1.056000e+03  1.090000e+03\n",
       "r1_lh                        2.000000e+01  9.000000e+00  2.200000e+01  1.400000e+01  8.000000e+00\n",
       "r1_kills                     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00\n",
       "r1_deaths                    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "r1_items                     7.000000e+00  1.200000e+01  1.200000e+01  5.000000e+00  8.000000e+00\n",
       "r2_hero                      6.700000e+01  4.900000e+01  9.800000e+01  3.000000e+01  2.700000e+01\n",
       "r2_level                     3.000000e+00  4.000000e+00  3.000000e+00  2.000000e+00  2.000000e+00\n",
       "r2_xp                        8.420000e+02  1.596000e+03  1.314000e+03  5.390000e+02  6.290000e+02\n",
       "r2_gold                      9.910000e+02  9.930000e+02  7.750000e+02  5.390000e+02  5.520000e+02\n",
       "r2_lh                        1.000000e+01  1.000000e+01  6.000000e+00  1.000000e+00  0.000000e+00\n",
       "r2_kills                     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "r2_deaths                    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00\n",
       "r2_items                     4.000000e+00  7.000000e+00  6.000000e+00  6.000000e+00  7.000000e+00\n",
       "r3_hero                      2.900000e+01  6.700000e+01  2.000000e+01  7.500000e+01  3.000000e+01\n",
       "r3_level                     5.000000e+00  4.000000e+00  3.000000e+00  5.000000e+00  3.000000e+00\n",
       "...                                   ...           ...           ...           ...           ...\n",
       "radiant_flying_courier_time  2.440000e+02           NaN           NaN           NaN  1.810000e+02\n",
       "radiant_tpscroll_count       2.000000e+00  2.000000e+00  2.000000e+00  0.000000e+00  1.000000e+00\n",
       "radiant_boots_count          2.000000e+00  0.000000e+00  5.000000e+00  3.000000e+00  4.000000e+00\n",
       "radiant_ward_observer_count  2.000000e+00  2.000000e+00  2.000000e+00  2.000000e+00  2.000000e+00\n",
       "radiant_ward_sentry_count    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
       "radiant_first_ward_time      3.500000e+01 -2.000000e+01 -3.900000e+01 -3.000000e+01  4.600000e+01\n",
       "dire_bottle_time             1.030000e+02  1.490000e+02  4.500000e+01  1.240000e+02  1.820000e+02\n",
       "dire_courier_time           -8.400000e+01 -8.400000e+01 -7.700000e+01 -8.000000e+01 -8.000000e+01\n",
       "dire_flying_courier_time     2.210000e+02  1.950000e+02  2.210000e+02  1.840000e+02  2.250000e+02\n",
       "dire_tpscroll_count          3.000000e+00  5.000000e+00  3.000000e+00  0.000000e+00  6.000000e+00\n",
       "dire_boots_count             4.000000e+00  4.000000e+00  4.000000e+00  4.000000e+00  3.000000e+00\n",
       "dire_ward_observer_count     2.000000e+00  3.000000e+00  3.000000e+00  2.000000e+00  3.000000e+00\n",
       "dire_ward_sentry_count       2.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
       "dire_first_ward_time        -5.200000e+01 -5.000000e+00  1.300000e+01  2.700000e+01 -1.600000e+01\n",
       "duration                     2.874000e+03  2.463000e+03  2.130000e+03  1.459000e+03  2.449000e+03\n",
       "radiant_win                  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "tower_status_radiant         1.796000e+03  1.974000e+03  0.000000e+00  1.920000e+03  4.000000e+00\n",
       "tower_status_dire            0.000000e+00  0.000000e+00  1.830000e+03  2.047000e+03  1.974000e+03\n",
       "barracks_status_radiant      5.100000e+01  6.300000e+01  0.000000e+00  5.000000e+01  3.000000e+00\n",
       "barracks_status_dire         0.000000e+00  1.000000e+00  6.300000e+01  6.300000e+01  6.300000e+01\n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>95404.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.444232e+09</td>\n",
       "      <td>2.630999</td>\n",
       "      <td>51.517104</td>\n",
       "      <td>3.442672</td>\n",
       "      <td>1233.405801</td>\n",
       "      <td>1147.899702</td>\n",
       "      <td>11.231996</td>\n",
       "      <td>0.357009</td>\n",
       "      <td>0.362285</td>\n",
       "      <td>8.271315</td>\n",
       "      <td>...</td>\n",
       "      <td>3.349553</td>\n",
       "      <td>2.448339</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>-6.901922</td>\n",
       "      <td>2332.247886</td>\n",
       "      <td>0.518503</td>\n",
       "      <td>1309.227790</td>\n",
       "      <td>1286.310820</td>\n",
       "      <td>40.599095</td>\n",
       "      <td>41.337036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.515393e+06</td>\n",
       "      <td>2.835761</td>\n",
       "      <td>32.564211</td>\n",
       "      <td>1.111741</td>\n",
       "      <td>566.588895</td>\n",
       "      <td>464.111662</td>\n",
       "      <td>9.041620</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>2.497575</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155609</td>\n",
       "      <td>0.813459</td>\n",
       "      <td>0.710122</td>\n",
       "      <td>40.701397</td>\n",
       "      <td>715.806850</td>\n",
       "      <td>0.499660</td>\n",
       "      <td>853.921365</td>\n",
       "      <td>851.009148</td>\n",
       "      <td>27.871645</td>\n",
       "      <td>27.064873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.430199e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.440815e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>1818.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446338e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1113.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1824.000000</td>\n",
       "      <td>1798.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.448829e+09</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2778.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.450313e+09</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3319.000000</td>\n",
       "      <td>4332.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>8452.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time    lobby_type       r1_hero      r1_level         r1_xp       r1_gold  \\\n",
       "count  9.723000e+04  97230.000000  97230.000000  97230.000000  97230.000000  97230.000000   \n",
       "mean   1.444232e+09      2.630999     51.517104      3.442672   1233.405801   1147.899702   \n",
       "std    5.515393e+06      2.835761     32.564211      1.111741    566.588895    464.111662   \n",
       "min    1.430199e+09      0.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%    1.440815e+09      1.000000     22.000000      3.000000    767.000000    746.000000   \n",
       "50%    1.446338e+09      1.000000     50.000000      3.000000   1175.000000   1113.000000   \n",
       "75%    1.448829e+09      7.000000     75.000000      4.000000   1704.000000   1479.000000   \n",
       "max    1.450313e+09      7.000000    112.000000      6.000000   3319.000000   4332.000000   \n",
       "\n",
       "              r1_lh      r1_kills     r1_deaths      r1_items          ...           \\\n",
       "count  97230.000000  97230.000000  97230.000000  97230.000000          ...            \n",
       "mean      11.231996      0.357009      0.362285      8.271315          ...            \n",
       "std        9.041620      0.663889      0.626704      2.497575          ...            \n",
       "min        0.000000      0.000000      0.000000      0.000000          ...            \n",
       "25%        2.000000      0.000000      0.000000      7.000000          ...            \n",
       "50%       11.000000      0.000000      0.000000      8.000000          ...            \n",
       "75%       19.000000      1.000000      1.000000     10.000000          ...            \n",
       "max       47.000000      8.000000      5.000000     34.000000          ...            \n",
       "\n",
       "       dire_boots_count  dire_ward_observer_count  dire_ward_sentry_count  dire_first_ward_time  \\\n",
       "count      97230.000000              97230.000000            97230.000000          95404.000000   \n",
       "mean           3.349553                  2.448339                0.689119             -6.901922   \n",
       "std            1.155609                  0.813459                0.710122             40.701397   \n",
       "min            0.000000                  0.000000                0.000000            -84.000000   \n",
       "25%            3.000000                  2.000000                0.000000            -31.000000   \n",
       "50%            3.000000                  2.000000                1.000000            -16.000000   \n",
       "75%            4.000000                  3.000000                1.000000              8.000000   \n",
       "max            9.000000                  9.000000               13.000000            300.000000   \n",
       "\n",
       "           duration   radiant_win  tower_status_radiant  tower_status_dire  \\\n",
       "count  97230.000000  97230.000000          97230.000000       97230.000000   \n",
       "mean    2332.247886      0.518503           1309.227790        1286.310820   \n",
       "std      715.806850      0.499660            853.921365         851.009148   \n",
       "min      900.000000      0.000000              0.000000           0.000000   \n",
       "25%     1818.000000      0.000000             36.000000         256.000000   \n",
       "50%     2268.000000      1.000000           1824.000000        1798.000000   \n",
       "75%     2778.000000      1.000000           1974.000000        1974.000000   \n",
       "max     8452.000000      1.000000           2047.000000        2047.000000   \n",
       "\n",
       "       barracks_status_radiant  barracks_status_dire  \n",
       "count             97230.000000          97230.000000  \n",
       "mean                 40.599095             41.337036  \n",
       "std                  27.871645             27.064873  \n",
       "min                   0.000000              0.000000  \n",
       "25%                   3.000000              3.000000  \n",
       "50%                  63.000000             60.000000  \n",
       "75%                  63.000000             63.000000  \n",
       "max                  63.000000             63.000000  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим переменные из будущего и время начала игры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['start_time','duration','tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant',\n",
    "       'barracks_status_dire'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>r2_hero</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>95394.000000</td>\n",
       "      <td>81087.000000</td>\n",
       "      <td>96554.000000</td>\n",
       "      <td>71132.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>95404.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.630999</td>\n",
       "      <td>51.517104</td>\n",
       "      <td>3.442672</td>\n",
       "      <td>1233.405801</td>\n",
       "      <td>1147.899702</td>\n",
       "      <td>11.231996</td>\n",
       "      <td>0.357009</td>\n",
       "      <td>0.362285</td>\n",
       "      <td>8.271315</td>\n",
       "      <td>52.183452</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.875747</td>\n",
       "      <td>127.215028</td>\n",
       "      <td>-80.191893</td>\n",
       "      <td>214.870536</td>\n",
       "      <td>2.965566</td>\n",
       "      <td>3.349553</td>\n",
       "      <td>2.448339</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>-6.901922</td>\n",
       "      <td>0.518503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.835761</td>\n",
       "      <td>32.564211</td>\n",
       "      <td>1.111741</td>\n",
       "      <td>566.588895</td>\n",
       "      <td>464.111662</td>\n",
       "      <td>9.041620</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>2.497575</td>\n",
       "      <td>32.674077</td>\n",
       "      <td>...</td>\n",
       "      <td>39.508650</td>\n",
       "      <td>62.442018</td>\n",
       "      <td>15.261950</td>\n",
       "      <td>34.137158</td>\n",
       "      <td>1.907288</td>\n",
       "      <td>1.155609</td>\n",
       "      <td>0.813459</td>\n",
       "      <td>0.710122</td>\n",
       "      <td>40.701397</td>\n",
       "      <td>0.499660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-236.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1113.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3319.000000</td>\n",
       "      <td>4332.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lobby_type       r1_hero      r1_level         r1_xp       r1_gold         r1_lh  \\\n",
       "count  97230.000000  97230.000000  97230.000000  97230.000000  97230.000000  97230.000000   \n",
       "mean       2.630999     51.517104      3.442672   1233.405801   1147.899702     11.231996   \n",
       "std        2.835761     32.564211      1.111741    566.588895    464.111662      9.041620   \n",
       "min        0.000000      1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000     22.000000      3.000000    767.000000    746.000000      2.000000   \n",
       "50%        1.000000     50.000000      3.000000   1175.000000   1113.000000     11.000000   \n",
       "75%        7.000000     75.000000      4.000000   1704.000000   1479.000000     19.000000   \n",
       "max        7.000000    112.000000      6.000000   3319.000000   4332.000000     47.000000   \n",
       "\n",
       "           r1_kills     r1_deaths      r1_items       r2_hero      ...       \\\n",
       "count  97230.000000  97230.000000  97230.000000  97230.000000      ...        \n",
       "mean       0.357009      0.362285      8.271315     52.183452      ...        \n",
       "std        0.663889      0.626704      2.497575     32.674077      ...        \n",
       "min        0.000000      0.000000      0.000000      1.000000      ...        \n",
       "25%        0.000000      0.000000      7.000000     25.000000      ...        \n",
       "50%        0.000000      0.000000      8.000000     50.000000      ...        \n",
       "75%        1.000000      1.000000     10.000000     75.000000      ...        \n",
       "max        8.000000      5.000000     34.000000    112.000000      ...        \n",
       "\n",
       "       radiant_first_ward_time  dire_bottle_time  dire_courier_time  dire_flying_courier_time  \\\n",
       "count             95394.000000      81087.000000       96554.000000              71132.000000   \n",
       "mean                 -6.875747        127.215028         -80.191893                214.870536   \n",
       "std                  39.508650         62.442018          15.261950                 34.137158   \n",
       "min                -236.000000        -45.000000         -90.000000                180.000000   \n",
       "25%                 -31.000000         83.000000         -86.000000                185.000000   \n",
       "50%                 -15.000000        131.000000         -84.000000                203.000000   \n",
       "75%                   9.000000        165.000000         -79.000000                238.000000   \n",
       "max                 300.000000        300.000000         296.000000                300.000000   \n",
       "\n",
       "       dire_tpscroll_count  dire_boots_count  dire_ward_observer_count  dire_ward_sentry_count  \\\n",
       "count         97230.000000      97230.000000              97230.000000            97230.000000   \n",
       "mean              2.965566          3.349553                  2.448339                0.689119   \n",
       "std               1.907288          1.155609                  0.813459                0.710122   \n",
       "min               0.000000          0.000000                  0.000000                0.000000   \n",
       "25%               2.000000          3.000000                  2.000000                0.000000   \n",
       "50%               3.000000          3.000000                  2.000000                1.000000   \n",
       "75%               4.000000          4.000000                  3.000000                1.000000   \n",
       "max              21.000000          9.000000                  9.000000               13.000000   \n",
       "\n",
       "       dire_first_ward_time   radiant_win  \n",
       "count          95404.000000  97230.000000  \n",
       "mean              -6.901922      0.518503  \n",
       "std               40.701397      0.499660  \n",
       "min              -84.000000      0.000000  \n",
       "25%              -31.000000      0.000000  \n",
       "50%              -16.000000      1.000000  \n",
       "75%                8.000000      1.000000  \n",
       "max              300.000000      1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Найдем пустые значения и заменим их нулями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных 97230 строк, поэтому любой столбец с меньшим числом значений имеет пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed values:\n",
      "\n",
      "first_blood_time               77677\n",
      "first_blood_team               77677\n",
      "first_blood_player1            77677\n",
      "first_blood_player2            53243\n",
      "radiant_bottle_time            81539\n",
      "radiant_courier_time           96538\n",
      "radiant_flying_courier_time    69751\n",
      "radiant_first_ward_time        95394\n",
      "dire_bottle_time               81087\n",
      "dire_courier_time              96554\n",
      "dire_flying_courier_time       71132\n",
      "dire_first_ward_time           95404\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = data.count() \n",
    "print('Missed values:\\n\\n{}\\n'.format(r[r<97230]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти столбцы описывают некоторые события в игре, и если событие не произошло, то в столбцах будут пустые значения. Заполняем пустые значения нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечем столбец с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.pop('radiant_win')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом мы добавим к данным мешок героев и чтобы в будущем мы смогли легко выделить исходные данные\n",
    "сейчас мы сохраним исходный список колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_columns = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сформируем мешок героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique heroes: 108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создадим группы колонок с Героями, чтобы потом их можно было легко использовать в будущем\n",
    "r_heroes_cols = ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero']\n",
    "d_heroes_cols = ['d1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "\n",
    "# Колонки с героями обеих команд\n",
    "heroes_cols = r_heroes_cols + d_heroes_cols\n",
    "\n",
    "# Объединим все колонки с героями из тренировочных данных и из тестовых данных\n",
    "# Хотя маловероятно, что в тестовых данных есть герои, которые не использовались\n",
    "# в тренировочных, но все же сделаем это\n",
    "heroes = data[heroes_cols].append(test[heroes_cols])\n",
    "# Получим массив с уникальными id героев\n",
    "unique_heroes = np.unique(heroes.values)\n",
    "# Количество героев - это размерность массива\n",
    "print('Number of unique heroes: {}\\n'.format(unique_heroes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сформируем мешок из героев\n",
    "for i in unique_heroes:\n",
    "    # Сформируем название столбца вида h_1, h_2 и т.д.\n",
    "    h_name = 'h_'+str(i)\n",
    "    # Выведем название столбца для оценки прогресса\n",
    "    # print(h_name)\n",
    "    # По всем столбцам с героями команды сделаем сравнение значения с id героя\n",
    "    # Если номер героя совпадет, то в результате будет True, иначе False\n",
    "    # Сделав сумму по всем таким полям каждой строчки мы получим 1, если\n",
    "    # есть True, или 0, если нет True\n",
    "    # Поскольку за игру герой может использоваться лишь 1 раз, то возможные значения {0, 1}\n",
    "    \n",
    "    # r - это столбец с 0 или 1 для данного героя в команде Radiant\n",
    "    r = (data[r_heroes_cols]==i).sum(axis=1)\n",
    "    # d - это аналогичный столбец с 0 или 1 для данного героя в команде Dire\n",
    "    d = (data[d_heroes_cols]==i).sum(axis=1)\n",
    "    # Разница между столбцами даст другой столбец с {-1,0,1}\n",
    "    # Этот столбец мы тут же добавляем в DataFrame data \n",
    "    data[h_name] = r - d\n",
    "    \n",
    "    # Аналогично сделаем для тестовой выборки\n",
    "    r = (test[r_heroes_cols]==i).sum(axis=1)\n",
    "    d = (test[d_heroes_cols]==i).sum(axis=1)\n",
    "    test[h_name] = r - d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование параметров метода Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Так как наши данные теперь содержат и мешок героев, то выделим в X только исходные столбцы\n",
    "X = data[original_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую (30%). \n",
    "# Это не является необходимым, просто для интереса.    \n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.3)\n",
    "# Подготовим KFold для кросс-валидации\n",
    "cv = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "     estimators  max_depth  learn_rate  KFold score  Hold score                       time\n",
      "1          10.0        1.0        0.05     0.599661    0.607962  0 days 00:00:07.180010000\n",
      "2          10.0        1.0        0.10     0.626783    0.627959  0 days 00:00:06.590009000\n",
      "3          10.0        1.0        0.20     0.638272    0.641854  0 days 00:00:06.610010000\n",
      "4          10.0        1.0        0.30     0.652657    0.654637  0 days 00:00:06.590009000\n",
      "5          10.0        1.0        0.50     0.652160    0.654358  0 days 00:00:06.540009000\n",
      "6          10.0        1.0        1.00     0.654329    0.655055  0 days 00:00:06.590009000\n",
      "7          10.0        3.0        0.05     0.640324    0.643410  0 days 00:00:20.950030000\n",
      "8          10.0        3.0        0.10     0.662926    0.668849  0 days 00:00:21.680030000\n",
      "9          10.0        3.0        0.20     0.676526    0.680052  0 days 00:00:22.310031000\n",
      "10         10.0        3.0        0.30     0.680924    0.685862  0 days 00:00:21.870031000\n",
      "11         10.0        3.0        0.50     0.684124    0.688655  0 days 00:00:21.940030000\n",
      "12         10.0        3.0        1.00     0.679858    0.687612  0 days 00:00:21.920031000\n",
      "13         10.0        5.0        0.05     0.659509    0.666926  0 days 00:00:54.170076000\n",
      "14         10.0        5.0        0.10     0.676485    0.681088  0 days 00:00:49.889231000\n",
      "15         10.0        5.0        0.20     0.686230    0.690952  0 days 00:00:49.535222000\n",
      "16         10.0        5.0        0.30     0.687475    0.691683  0 days 00:00:49.120132000\n",
      "17         10.0        5.0        0.50     0.686817    0.694555  0 days 00:00:49.464097000\n",
      "18         10.0        5.0        1.00     0.675507    0.684563  0 days 00:00:49.728160000\n",
      "19         10.0        7.0        0.05     0.670246    0.675226  0 days 00:02:06.170178000\n",
      "20         10.0        7.0        0.10     0.682286    0.685764  0 days 00:02:06.058178000\n",
      "21         10.0        7.0        0.20     0.685540    0.692358  0 days 00:02:05.846321000\n",
      "22         10.0        7.0        0.30     0.684614    0.691071  0 days 00:02:05.884473000\n",
      "23         10.0        7.0        0.50     0.674821    0.687420  0 days 00:02:03.628180000\n",
      "24         10.0        7.0        1.00     0.655352    0.662998  0 days 00:02:02.171334000\n",
      "25         20.0        1.0        0.05     0.626021    0.628974  0 days 00:00:10.350014000\n",
      "..          ...        ...         ...          ...         ...                        ...\n",
      "168       200.0        7.0        1.00     0.643635    0.649569  0 days 00:33:48.971051000\n",
      "169       250.0        1.0        0.05     0.692493    0.696212  0 days 00:01:41.751819000\n",
      "170       250.0        1.0        0.10     0.701576    0.706408  0 days 00:01:46.038065000\n",
      "171       250.0        1.0        0.20     0.708340    0.713655  0 days 00:01:42.504863000\n",
      "172       250.0        1.0        0.30     0.711751    0.716329  0 days 00:01:43.566923000\n",
      "173       250.0        1.0        0.50     0.714427    0.718722  0 days 00:01:42.812881000\n",
      "174       250.0        1.0        1.00     0.713280    0.719869  0 days 00:01:41.287793000\n",
      "175       250.0        3.0        0.05     0.707051    0.711647  0 days 00:07:22.789326000\n",
      "176       250.0        3.0        0.10     0.713624    0.718149  0 days 00:07:32.826900000\n",
      "177       250.0        3.0        0.20     0.715983    0.720970  0 days 00:07:46.565686000\n",
      "178       250.0        3.0        0.30     0.712023    0.719810  0 days 00:07:34.851016000\n",
      "179       250.0        3.0        0.50     0.702127    0.711747  0 days 00:07:42.452451000\n",
      "180       250.0        3.0        1.00     0.675088    0.687095  0 days 00:07:57.638319000\n",
      "181       250.0        5.0        0.05     0.711150    0.717981  0 days 00:20:58.237967000\n",
      "182       250.0        5.0        0.10     0.713451    0.720686  0 days 00:19:11.437858000\n",
      "183       250.0        5.0        0.20     0.705156    0.716245  0 days 00:18:32.399626000\n",
      "184       250.0        5.0        0.30     0.695061    0.706368  0 days 00:18:00.968828000\n",
      "185       250.0        5.0        0.50     0.673548    0.686126  0 days 00:17:00.542372000\n",
      "186       250.0        5.0        1.00     0.641845    0.648708  0 days 00:19:28.385828000\n",
      "187       250.0        7.0        0.05     0.710434    0.719434  0 days 00:48:00.174736000\n",
      "188       250.0        7.0        0.10     0.705206    0.717108  0 days 00:44:54.859137000\n",
      "189       250.0        7.0        0.20     0.692736    0.699309  0 days 00:43:17.299121000\n",
      "190       250.0        7.0        0.30     0.681839    0.686409  0 days 00:44:05.951339000\n",
      "191       250.0        7.0        0.50     0.664513    0.672598  0 days 00:46:50.059726000\n",
      "192       250.0        7.0        1.00     0.646592    0.651638  0 days 00:59:43.226949000\n",
      "\n",
      "[192 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Далее проведем подбор параметров. \n",
    "# Поскольку код выполняется достаточно долго (~сутки),\n",
    "# то мы сделаем это лишь один раз и сохраним результаты в файл.\n",
    "# Если нам в следующий раз потребуются результаты, то нет необходимости делать\n",
    "# вычисления снова - мы просто загрузим данные из файла.\n",
    "# Чтобы снова проделать вычисления - после if нужно поставить True\n",
    "if False:    \n",
    "    # Список возможных значений параметров\n",
    "    # Число деревьев\n",
    "    estimators = [10, 20, 30, 50, 100, 150, 200, 250]\n",
    "    # Максимальная глубина деревьев\n",
    "    max_depth = [1, 3, 5, 7]\n",
    "    # Переменная learning rate\n",
    "    ''' \n",
    "    scikit-learn documentation:\n",
    "    \"The learning_rate is a hyper-parameter in the range (0.0, 1.0] that controls overfitting via shrinkage.\n",
    "    \n",
    "    Learning rate scales the step length the gradient descent procedure.\n",
    "    The parameter learning_rate strongly interacts with the parameter n_estimators. \n",
    "    Smaller values of learning_rate require larger numbers of weak learners to maintain a constant training error. \n",
    "    Empirical evidence suggests that small values of learning_rate favor better test error. \n",
    "    [HTF2009] recommend to set the learning rate to a small constant (e.g. learning_rate <= 0.1) \n",
    "    and choose n_estimators by early stopping.\"\n",
    "    \n",
    "    Boschetti, Massaron - Python Data Science essentials (2015)\n",
    "    • n_estimators: Exceeding with estimators, it increases variance. Anyway,\n",
    "    if the estimators are not enough, the algorithm will suffer from high bias.\n",
    "    • max_depth: It increases the variance and complexity.\n",
    "    • subsample: It can effectively reduce variance.\n",
    "    • learning_rate: Smaller values can improve optimization in the training process, \n",
    "    though it will require more estimators to converge, and thus more computational time.\n",
    "    • min_samples_leaf: It can reduce the variance due to noisy data, reserving overfitting to rare cases.\"\n",
    "    \n",
    "    Поскольку каждое последующее дерево работает с ошибками предыдущего, \n",
    "    то learning_rate описывает скорость устранения этих ошибок. \n",
    "    Если learning_rate маленький, то шаги маленькие, в итоге нужно много деревьев, \n",
    "    каждое из которых приближает решение по чуть-чуть.\n",
    "    Если learning_rate большой, то ошибки исправляются резкими скачками, \n",
    "    и решение приближается быстрее, но за счет этого теряется точность.\n",
    "    Пока что это лишь гипотеза, которую я попробую проверить на текущих данных.\n",
    "    '''\n",
    "    # Поскольку в лекциях ничего про shrinkage не говорилось, попробуем\n",
    "    # помимо прочего оценить влияние learning_rate на результат.\n",
    "    # Вдруг будет что-то интересное\n",
    "    learning_rate = [0.05, 0.1, 0.2, 0.3, 0.5, 1.0]\n",
    "    # combs_cnt - просто число различных комбинаций параметров, для оценки прогресса выполнения кода\n",
    "    combs_cnt = len(estimators) * len(max_depth) * len(learning_rate)\n",
    "\n",
    "    # Просто счетчик итераций\n",
    "    i = 1    \n",
    "    # DataFrame, куда мы будем записывать результаты на каждой итерации\n",
    "    r = DataFrame([])\n",
    "    \n",
    "    # Перебираем все значения параметров       \n",
    "    for k in estimators:\n",
    "        for d in max_depth:\n",
    "            for lr in learning_rate:    \n",
    "                # Создаем классификатор с указанными параметрами\n",
    "                clf = GradientBoostingClassifier(n_estimators=k,\n",
    "                                                 learning_rate=lr,\n",
    "                                                 max_depth=d)\n",
    "                start_time = datetime.now()\n",
    "                # Поскольку cross_val_score возвращает массив с результатами,\n",
    "                # то мы его сразу же и усредним\n",
    "                score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv, scoring='roc_auc').mean()\n",
    "                end_time = datetime.now()\n",
    "                \n",
    "                # Теперь оценим результат по отложенной выборке\n",
    "                clf = GradientBoostingClassifier(n_estimators=k,\n",
    "                                                 learning_rate=lr,\n",
    "                                                 max_depth=d)                \n",
    "                clf.fit(X_train, y_train)\n",
    "                y_hold_pred = clf.predict_proba(X_hold)\n",
    "                on_hold_score = roc_auc_score(y_hold, y_hold_pred[:,1])\n",
    "                \n",
    "                # Запишем результаты в DataFrame\n",
    "                r.loc[i, 'estimators'] = k\n",
    "                r.loc[i, 'max_depth'] = d\n",
    "                r.loc[i, 'learn_rate'] = lr\n",
    "                r.loc[i, 'KFold score'] = score                \n",
    "                r.loc[i, 'Hold score'] = on_hold_score\n",
    "                r.loc[i, 'time'] = end_time-start_time\n",
    "                # Выведем на экран текущие результаты для контроля прогресса\n",
    "                print('Step {}/{}:\\n{}\\n'.format(i, combs_cnt, r))\n",
    "                i += 1\n",
    "    # Сохраним результаты, чтобы не пришлось считать снова            \n",
    "    r.to_csv('./data/evaluation_result_3.csv', index=True, header=True)                \n",
    "    print('FINISHED!')\n",
    "else:\n",
    "    # Загрузим полученные ранее результаты\n",
    "    r = pd.read_csv('./data/evaluation_result_3.csv', index_col=0)\n",
    "\n",
    "# Выведем итоговые результаты\n",
    "pd.set_option('display.width', 100)\n",
    "print('Final results:\\n{}\\n'.format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>KFold score</th>\n",
       "      <th>Hold score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>0.642726</td>\n",
       "      <td>0 days 00:00:15.116864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.665015</td>\n",
       "      <td>0.671152</td>\n",
       "      <td>0 days 00:00:15.014859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.677868</td>\n",
       "      <td>0.679821</td>\n",
       "      <td>0 days 00:00:15.132865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.684936</td>\n",
       "      <td>0.688463</td>\n",
       "      <td>0 days 00:00:14.931854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.687496</td>\n",
       "      <td>0.690758</td>\n",
       "      <td>0 days 00:00:15.165868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.690789</td>\n",
       "      <td>0.696425</td>\n",
       "      <td>0 days 00:00:15.002858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.675403</td>\n",
       "      <td>0.679627</td>\n",
       "      <td>0 days 00:00:57.046263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.690859</td>\n",
       "      <td>0 days 00:00:57.295277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.695145</td>\n",
       "      <td>0.700643</td>\n",
       "      <td>0 days 00:00:57.482288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.699068</td>\n",
       "      <td>0.704040</td>\n",
       "      <td>0 days 00:00:57.002260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.700064</td>\n",
       "      <td>0.705115</td>\n",
       "      <td>0 days 00:00:57.042262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.691428</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0 days 00:00:55.909198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.686760</td>\n",
       "      <td>0.691953</td>\n",
       "      <td>0 days 00:02:28.935518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.695620</td>\n",
       "      <td>0.700719</td>\n",
       "      <td>0 days 00:02:30.018581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.700592</td>\n",
       "      <td>0.706494</td>\n",
       "      <td>0 days 00:02:30.815626000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>0.704592</td>\n",
       "      <td>0 days 00:02:26.974407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.692508</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0 days 00:02:24.553268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.668420</td>\n",
       "      <td>0.681676</td>\n",
       "      <td>0 days 00:02:22.343142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.692229</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>0 days 00:06:26.092083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.698219</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0 days 00:06:23.245920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.696791</td>\n",
       "      <td>0.702545</td>\n",
       "      <td>0 days 00:06:10.889213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.689250</td>\n",
       "      <td>0.696794</td>\n",
       "      <td>0 days 00:06:01.987704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.673488</td>\n",
       "      <td>0.684852</td>\n",
       "      <td>0 days 00:05:48.512934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.643777</td>\n",
       "      <td>0.652964</td>\n",
       "      <td>0 days 00:05:38.490361000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    estimators  max_depth  learn_rate  KFold score  Hold score                       time\n",
       "49        30.0        1.0        0.05     0.639419    0.642726  0 days 00:00:15.116864000\n",
       "50        30.0        1.0        0.10     0.665015    0.671152  0 days 00:00:15.014859000\n",
       "51        30.0        1.0        0.20     0.677868    0.679821  0 days 00:00:15.132865000\n",
       "52        30.0        1.0        0.30     0.684936    0.688463  0 days 00:00:14.931854000\n",
       "53        30.0        1.0        0.50     0.687496    0.690758  0 days 00:00:15.165868000\n",
       "54        30.0        1.0        1.00     0.690789    0.696425  0 days 00:00:15.002858000\n",
       "55        30.0        3.0        0.05     0.675403    0.679627  0 days 00:00:57.046263000\n",
       "56        30.0        3.0        0.10     0.687151    0.690859  0 days 00:00:57.295277000\n",
       "57        30.0        3.0        0.20     0.695145    0.700643  0 days 00:00:57.482288000\n",
       "58        30.0        3.0        0.30     0.699068    0.704040  0 days 00:00:57.002260000\n",
       "59        30.0        3.0        0.50     0.700064    0.705115  0 days 00:00:57.042262000\n",
       "60        30.0        3.0        1.00     0.691428    0.697934  0 days 00:00:55.909198000\n",
       "61        30.0        5.0        0.05     0.686760    0.691953  0 days 00:02:28.935518000\n",
       "62        30.0        5.0        0.10     0.695620    0.700719  0 days 00:02:30.018581000\n",
       "63        30.0        5.0        0.20     0.700592    0.706494  0 days 00:02:30.815626000\n",
       "64        30.0        5.0        0.30     0.698241    0.704592  0 days 00:02:26.974407000\n",
       "65        30.0        5.0        0.50     0.692508    0.702906  0 days 00:02:24.553268000\n",
       "66        30.0        5.0        1.00     0.668420    0.681676  0 days 00:02:22.343142000\n",
       "67        30.0        7.0        0.05     0.692229    0.696692  0 days 00:06:26.092083000\n",
       "68        30.0        7.0        0.10     0.698219    0.703650  0 days 00:06:23.245920000\n",
       "69        30.0        7.0        0.20     0.696791    0.702545  0 days 00:06:10.889213000\n",
       "70        30.0        7.0        0.30     0.689250    0.696794  0 days 00:06:01.987704000\n",
       "71        30.0        7.0        0.50     0.673488    0.684852  0 days 00:05:48.512934000\n",
       "72        30.0        7.0        1.00     0.643777    0.652964  0 days 00:05:38.490361000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[r['estimators']==30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим зависимости. Посмотрим, как соотносятся оценки по KFold и оценки по отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xbbb73c8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xba3e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g, ax = plt.subplots(1,1)\n",
    "ax.plot(r.index, r['KFold score'], color='b')\n",
    "ax.plot(r.index, r['Hold score'], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что KFold (синяя линия) дает более пессимистичную оценку, и это хорошо. KFold делает 5 проверок, \n",
    "что лучше, чем одна проверка на отложенной выборке. В дальнейшем анализе будем использовать только KFold валидацию.\n",
    "\n",
    "Так же мы видим, что точность растет с повышением количества деревьев. Похоже на, что лучшая точность находится\n",
    "в диапазоне 200-250 деревьев и при дальнейшем увеличении числа деревьев точность не будет расти. \n",
    "(Подписи у оси x показывают номер итерации, а не количество деревьев).\n",
    "\n",
    "На графиках видны резкие провалы и регулярные более мелкие провалы, это значит, что какой-то из параметров настольк \n",
    "сильно портит модель, что даже увеличенное количество деревьев не способно это исправить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем количество деревьев и найдем лучшие оценки для каждого фиксированного варианта количества деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimators\n",
       "10     0.687475\n",
       "20     0.695745\n",
       "30     0.700592\n",
       "50     0.705094\n",
       "100    0.711543\n",
       "150    0.712245\n",
       "200    0.714198\n",
       "250    0.715983\n",
       "Name: KFold score, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = r.groupby('estimators').max()['KFold score']\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Теперь мы соединим две таблицы по полю estimators, будет операция аналогичная SQL LEFT JOIN\n",
    "# Сделаем некоторые технические манипуляции. Возможно, их и не нужно делать, если pandas умеет делать join \n",
    "# по float полям. Лень проверять, умеет или нет, просто приведем поля к int.\n",
    "best=best.reset_index()\n",
    "best['estimators'] = best['estimators'].astype(int)\n",
    "r['estimators'] = r['estimators'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>KFold score_x</th>\n",
       "      <th>Hold score</th>\n",
       "      <th>time</th>\n",
       "      <th>KFold score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.599661</td>\n",
       "      <td>0.607962</td>\n",
       "      <td>0 days 00:00:07.180010000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.626783</td>\n",
       "      <td>0.627959</td>\n",
       "      <td>0 days 00:00:06.590009000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.638272</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>0 days 00:00:06.610010000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.652657</td>\n",
       "      <td>0.654637</td>\n",
       "      <td>0 days 00:00:06.590009000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.652160</td>\n",
       "      <td>0.654358</td>\n",
       "      <td>0 days 00:00:06.540009000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.654329</td>\n",
       "      <td>0.655055</td>\n",
       "      <td>0 days 00:00:06.590009000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.640324</td>\n",
       "      <td>0.643410</td>\n",
       "      <td>0 days 00:00:20.950030000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.662926</td>\n",
       "      <td>0.668849</td>\n",
       "      <td>0 days 00:00:21.680030000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.676526</td>\n",
       "      <td>0.680052</td>\n",
       "      <td>0 days 00:00:22.310031000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.680924</td>\n",
       "      <td>0.685862</td>\n",
       "      <td>0 days 00:00:21.870031000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.684124</td>\n",
       "      <td>0.688655</td>\n",
       "      <td>0 days 00:00:21.940030000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.679858</td>\n",
       "      <td>0.687612</td>\n",
       "      <td>0 days 00:00:21.920031000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.659509</td>\n",
       "      <td>0.666926</td>\n",
       "      <td>0 days 00:00:54.170076000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.676485</td>\n",
       "      <td>0.681088</td>\n",
       "      <td>0 days 00:00:49.889231000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.686230</td>\n",
       "      <td>0.690952</td>\n",
       "      <td>0 days 00:00:49.535222000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.687475</td>\n",
       "      <td>0.691683</td>\n",
       "      <td>0 days 00:00:49.120132000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.694555</td>\n",
       "      <td>0 days 00:00:49.464097000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.675507</td>\n",
       "      <td>0.684563</td>\n",
       "      <td>0 days 00:00:49.728160000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.670246</td>\n",
       "      <td>0.675226</td>\n",
       "      <td>0 days 00:02:06.170178000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>0.685764</td>\n",
       "      <td>0 days 00:02:06.058178000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.714427</td>\n",
       "      <td>0.718722</td>\n",
       "      <td>0 days 00:01:42.812881000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.713280</td>\n",
       "      <td>0.719869</td>\n",
       "      <td>0 days 00:01:41.287793000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.707051</td>\n",
       "      <td>0.711647</td>\n",
       "      <td>0 days 00:07:22.789326000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.713624</td>\n",
       "      <td>0.718149</td>\n",
       "      <td>0 days 00:07:32.826900000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.715983</td>\n",
       "      <td>0.720970</td>\n",
       "      <td>0 days 00:07:46.565686000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.712023</td>\n",
       "      <td>0.719810</td>\n",
       "      <td>0 days 00:07:34.851016000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.702127</td>\n",
       "      <td>0.711747</td>\n",
       "      <td>0 days 00:07:42.452451000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.675088</td>\n",
       "      <td>0.687095</td>\n",
       "      <td>0 days 00:07:57.638319000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.711150</td>\n",
       "      <td>0.717981</td>\n",
       "      <td>0 days 00:20:58.237967000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.713451</td>\n",
       "      <td>0.720686</td>\n",
       "      <td>0 days 00:19:11.437858000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.705156</td>\n",
       "      <td>0.716245</td>\n",
       "      <td>0 days 00:18:32.399626000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.695061</td>\n",
       "      <td>0.706368</td>\n",
       "      <td>0 days 00:18:00.968828000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.673548</td>\n",
       "      <td>0.686126</td>\n",
       "      <td>0 days 00:17:00.542372000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.641845</td>\n",
       "      <td>0.648708</td>\n",
       "      <td>0 days 00:19:28.385828000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.710434</td>\n",
       "      <td>0.719434</td>\n",
       "      <td>0 days 00:48:00.174736000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.705206</td>\n",
       "      <td>0.717108</td>\n",
       "      <td>0 days 00:44:54.859137000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.692736</td>\n",
       "      <td>0.699309</td>\n",
       "      <td>0 days 00:43:17.299121000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.681839</td>\n",
       "      <td>0.686409</td>\n",
       "      <td>0 days 00:44:05.951339000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.664513</td>\n",
       "      <td>0.672598</td>\n",
       "      <td>0 days 00:46:50.059726000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>250</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.646592</td>\n",
       "      <td>0.651638</td>\n",
       "      <td>0 days 00:59:43.226949000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     estimators  max_depth  learn_rate  KFold score_x  Hold score                       time  \\\n",
       "0            10        1.0        0.05       0.599661    0.607962  0 days 00:00:07.180010000   \n",
       "1            10        1.0        0.10       0.626783    0.627959  0 days 00:00:06.590009000   \n",
       "2            10        1.0        0.20       0.638272    0.641854  0 days 00:00:06.610010000   \n",
       "3            10        1.0        0.30       0.652657    0.654637  0 days 00:00:06.590009000   \n",
       "4            10        1.0        0.50       0.652160    0.654358  0 days 00:00:06.540009000   \n",
       "5            10        1.0        1.00       0.654329    0.655055  0 days 00:00:06.590009000   \n",
       "6            10        3.0        0.05       0.640324    0.643410  0 days 00:00:20.950030000   \n",
       "7            10        3.0        0.10       0.662926    0.668849  0 days 00:00:21.680030000   \n",
       "8            10        3.0        0.20       0.676526    0.680052  0 days 00:00:22.310031000   \n",
       "9            10        3.0        0.30       0.680924    0.685862  0 days 00:00:21.870031000   \n",
       "10           10        3.0        0.50       0.684124    0.688655  0 days 00:00:21.940030000   \n",
       "11           10        3.0        1.00       0.679858    0.687612  0 days 00:00:21.920031000   \n",
       "12           10        5.0        0.05       0.659509    0.666926  0 days 00:00:54.170076000   \n",
       "13           10        5.0        0.10       0.676485    0.681088  0 days 00:00:49.889231000   \n",
       "14           10        5.0        0.20       0.686230    0.690952  0 days 00:00:49.535222000   \n",
       "15           10        5.0        0.30       0.687475    0.691683  0 days 00:00:49.120132000   \n",
       "16           10        5.0        0.50       0.686817    0.694555  0 days 00:00:49.464097000   \n",
       "17           10        5.0        1.00       0.675507    0.684563  0 days 00:00:49.728160000   \n",
       "18           10        7.0        0.05       0.670246    0.675226  0 days 00:02:06.170178000   \n",
       "19           10        7.0        0.10       0.682286    0.685764  0 days 00:02:06.058178000   \n",
       "..          ...        ...         ...            ...         ...                        ...   \n",
       "172         250        1.0        0.50       0.714427    0.718722  0 days 00:01:42.812881000   \n",
       "173         250        1.0        1.00       0.713280    0.719869  0 days 00:01:41.287793000   \n",
       "174         250        3.0        0.05       0.707051    0.711647  0 days 00:07:22.789326000   \n",
       "175         250        3.0        0.10       0.713624    0.718149  0 days 00:07:32.826900000   \n",
       "176         250        3.0        0.20       0.715983    0.720970  0 days 00:07:46.565686000   \n",
       "177         250        3.0        0.30       0.712023    0.719810  0 days 00:07:34.851016000   \n",
       "178         250        3.0        0.50       0.702127    0.711747  0 days 00:07:42.452451000   \n",
       "179         250        3.0        1.00       0.675088    0.687095  0 days 00:07:57.638319000   \n",
       "180         250        5.0        0.05       0.711150    0.717981  0 days 00:20:58.237967000   \n",
       "181         250        5.0        0.10       0.713451    0.720686  0 days 00:19:11.437858000   \n",
       "182         250        5.0        0.20       0.705156    0.716245  0 days 00:18:32.399626000   \n",
       "183         250        5.0        0.30       0.695061    0.706368  0 days 00:18:00.968828000   \n",
       "184         250        5.0        0.50       0.673548    0.686126  0 days 00:17:00.542372000   \n",
       "185         250        5.0        1.00       0.641845    0.648708  0 days 00:19:28.385828000   \n",
       "186         250        7.0        0.05       0.710434    0.719434  0 days 00:48:00.174736000   \n",
       "187         250        7.0        0.10       0.705206    0.717108  0 days 00:44:54.859137000   \n",
       "188         250        7.0        0.20       0.692736    0.699309  0 days 00:43:17.299121000   \n",
       "189         250        7.0        0.30       0.681839    0.686409  0 days 00:44:05.951339000   \n",
       "190         250        7.0        0.50       0.664513    0.672598  0 days 00:46:50.059726000   \n",
       "191         250        7.0        1.00       0.646592    0.651638  0 days 00:59:43.226949000   \n",
       "\n",
       "     KFold score_y  \n",
       "0         0.687475  \n",
       "1         0.687475  \n",
       "2         0.687475  \n",
       "3         0.687475  \n",
       "4         0.687475  \n",
       "5         0.687475  \n",
       "6         0.687475  \n",
       "7         0.687475  \n",
       "8         0.687475  \n",
       "9         0.687475  \n",
       "10        0.687475  \n",
       "11        0.687475  \n",
       "12        0.687475  \n",
       "13        0.687475  \n",
       "14        0.687475  \n",
       "15        0.687475  \n",
       "16        0.687475  \n",
       "17        0.687475  \n",
       "18        0.687475  \n",
       "19        0.687475  \n",
       "..             ...  \n",
       "172       0.715983  \n",
       "173       0.715983  \n",
       "174       0.715983  \n",
       "175       0.715983  \n",
       "176       0.715983  \n",
       "177       0.715983  \n",
       "178       0.715983  \n",
       "179       0.715983  \n",
       "180       0.715983  \n",
       "181       0.715983  \n",
       "182       0.715983  \n",
       "183       0.715983  \n",
       "184       0.715983  \n",
       "185       0.715983  \n",
       "186       0.715983  \n",
       "187       0.715983  \n",
       "188       0.715983  \n",
       "189       0.715983  \n",
       "190       0.715983  \n",
       "191       0.715983  \n",
       "\n",
       "[192 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Собственно, сам JOIN\n",
    "best = pd.merge(r, best, how='left', on='estimators')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>KFold score_x</th>\n",
       "      <th>Hold score</th>\n",
       "      <th>time</th>\n",
       "      <th>KFold score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.687475</td>\n",
       "      <td>0.691683</td>\n",
       "      <td>0 days 00:00:49.120132000</td>\n",
       "      <td>0.687475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.695745</td>\n",
       "      <td>0.702515</td>\n",
       "      <td>0 days 00:01:36.935544000</td>\n",
       "      <td>0.695745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.700592</td>\n",
       "      <td>0.706494</td>\n",
       "      <td>0 days 00:02:30.815626000</td>\n",
       "      <td>0.700592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.705094</td>\n",
       "      <td>0.707738</td>\n",
       "      <td>0 days 00:01:29.519262000</td>\n",
       "      <td>0.705094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.711543</td>\n",
       "      <td>0.716436</td>\n",
       "      <td>0 days 00:02:53.293911000</td>\n",
       "      <td>0.711543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.712245</td>\n",
       "      <td>0.718576</td>\n",
       "      <td>0 days 00:05:02.178284000</td>\n",
       "      <td>0.712245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.714198</td>\n",
       "      <td>0.719223</td>\n",
       "      <td>0 days 00:05:41.593538000</td>\n",
       "      <td>0.714198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.715983</td>\n",
       "      <td>0.720970</td>\n",
       "      <td>0 days 00:07:46.565686000</td>\n",
       "      <td>0.715983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     estimators  max_depth  learn_rate  KFold score_x  Hold score                       time  \\\n",
       "15           10        5.0         0.3       0.687475    0.691683  0 days 00:00:49.120132000   \n",
       "39           20        5.0         0.3       0.695745    0.702515  0 days 00:01:36.935544000   \n",
       "62           30        5.0         0.2       0.700592    0.706494  0 days 00:02:30.815626000   \n",
       "82           50        3.0         0.5       0.705094    0.707738  0 days 00:01:29.519262000   \n",
       "105         100        3.0         0.3       0.711543    0.716436  0 days 00:02:53.293911000   \n",
       "129         150        3.0         0.3       0.712245    0.718576  0 days 00:05:02.178284000   \n",
       "152         200        3.0         0.2       0.714198    0.719223  0 days 00:05:41.593538000   \n",
       "176         250        3.0         0.2       0.715983    0.720970  0 days 00:07:46.565686000   \n",
       "\n",
       "     KFold score_y  \n",
       "15        0.687475  \n",
       "39        0.695745  \n",
       "62        0.700592  \n",
       "82        0.705094  \n",
       "105       0.711543  \n",
       "129       0.712245  \n",
       "152       0.714198  \n",
       "176       0.715983  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выберем лучшие результаты\n",
    "best_of_the_best = best[best['KFold score_x']==best['KFold score_y']]\n",
    "best_of_the_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При конструировании моделей мы использовали max_depth = {1, 3, 5, 7}. Видно, что при малом количестве деревьев лучше работают \n",
    "деревья с глубиной 5. Хотя был вариант с глубиной 7, все же оптимальной оказалась глубина 5. С ростом числа деревьев оптимальная\n",
    "глубина уменьшается и при 250 деревьях оптимальной является глубина 3.\n",
    "\n",
    "Что же касается learning_rate, то оптимальное значение находится в диапазоне 0,2-0,3. При этом выглядит так, что\n",
    "при увеличении числа деревьев 0,2 становится более оптимальным. Возможно, на каком-то этапе появится и 0,1.\n",
    "\n",
    "Нарисуем график лучших результатов при различном числе деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xbdc7d68>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbeb5550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g, ax = plt.subplots(1,1)\n",
    "ax.plot(best_of_the_best['estimators'], best_of_the_best['KFold score_x'], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит так, как будто еще есть потенциал для улучшения модели. \n",
    "Может быть 1000 деревьев с learning_rate 0.1 даст самый лучший результат? Возможно.\n",
    "\n",
    "Исследовать можно бесконечно, но наша цель - сдать зачет и получить сертификат. \n",
    "Поэтому тут мы остановимся в исследованиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение числа деревьев с помощью метода Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее приводилась строчка из документации scikit-learn:\n",
    "[HTF2009] recommend to set the learning rate to a small constant (e.g. learning_rate <= 0.1) \n",
    "and choose n_estimators by early stopping.\n",
    "\n",
    "Выглядит так, как будто эта рекомендация действительно нам подходит. Попробуем ее использовать. \n",
    "Мы используем ту же подвыборку X_test, y_test и ту же KFold валидацию, чтобы результаты были получены в сходных условиях. \n",
    "Кроме того, мы используем Stochastic Gradient Boosting, что, согласно теории, даст нам более точную модель и ускорит ее обучение. Так же мы используем warm_start, что позволит при увеличении числа деревьев \"наращивать\" старую модель, а не создавать ее с нуля. Это ускорит обучение. Мы не будем останавливаться на лучшем результате, как это требует early stopping, а просто обучим несколько лишних моделей.\n",
    "\n",
    "Если бы это была \"боевая\" задача, то, конечно, имело бы смысл сделать все более аккуратно и использовать не тестовую \n",
    "подвыборку, а полный набор значений, и т.д.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "    n_estimators     score  Hold score                       time\n",
      "1          250.0  0.749587    0.713095  0 days 00:02:18.908114000\n",
      "2          300.0  0.755107    0.713736  0 days 00:00:32.698870000\n",
      "3          350.0  0.760248    0.714710  0 days 00:00:31.584807000\n",
      "4          400.0  0.765024    0.715554  0 days 00:00:30.174726000\n",
      "5          450.0  0.769932    0.716094  0 days 00:00:30.586749000\n",
      "6          500.0  0.774311    0.716737  0 days 00:00:30.368737000\n",
      "7          550.0  0.778452    0.716963  0 days 00:00:31.690812000\n",
      "8          600.0  0.782271    0.717178  0 days 00:00:34.992002000\n",
      "9          650.0  0.786215    0.717442  0 days 00:00:31.380795000\n",
      "10         700.0  0.789981    0.717426  0 days 00:00:29.568691000\n",
      "11         750.0  0.793526    0.717678  0 days 00:00:29.114665000\n",
      "12         800.0  0.796875    0.717640  0 days 00:00:28.732643000\n",
      "13         850.0  0.800190    0.717249  0 days 00:00:29.198670000\n",
      "14         900.0  0.803545    0.717258  0 days 00:00:29.190670000\n",
      "15         950.0  0.806581    0.717314  0 days 00:00:29.358679000\n",
      "16        1000.0  0.809539    0.717047  0 days 00:00:30.869766000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    clf = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                     max_depth=3, \n",
    "                                     warm_start=True,\n",
    "                                     subsample=0.50)\n",
    "    \n",
    "    # DataFrame c результатами\n",
    "    r_2 = DataFrame([])\n",
    "    # Просто индекс\n",
    "    i=1\n",
    "    \n",
    "    # Если этого не сделать, то будет выводиться ошибка\n",
    "    X_train = np.ascontiguousarray(X_train.values)\n",
    "    \n",
    "    for k in range(250, 1050, 50):\n",
    "        print('\\nStart with {} trees'.format(k))\n",
    "        clf.n_estimators = k\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        # Результат на обучаемых данных\n",
    "        y_pred = clf.predict_proba(X_train)\n",
    "        score = roc_auc_score(y_train, y_pred[:,1])\n",
    "        \n",
    "        # Результат на отложенной выборке\n",
    "        y_hold_pred = clf.predict_proba(X_hold)\n",
    "        on_hold_score = roc_auc_score(y_hold, y_hold_pred[:,1])\n",
    "        \n",
    "        r_2.loc[i, 'n_estimators'] = k\n",
    "        r_2.loc[i, 'score'] = score \n",
    "        r_2.loc[i, 'Hold score'] = on_hold_score                \n",
    "        r_2.loc[i, 'time'] = end_time-start_time       \n",
    "        print(r_2)    \n",
    "        i += 1\n",
    "    \n",
    "    r_2.to_csv('./data/early_stopping_result.csv', index=True, header=True)                \n",
    "    print('FINISHED!')           \n",
    "else:\n",
    "    r_2 = pd.read_csv('./data/early_stopping_result.csv', index_col=0)\n",
    "    \n",
    "# Выведем итоговые результаты\n",
    "print('Final results:\\n{}\\n'.format(r_2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что warm_start работает - первая модель тренировалась 2 минуты. Каждая следующая модель тренируется около 30 сек.\n",
    "\n",
    "Так же видим, что модели переобучаются начиная с некоторого числа деревьев. Нарисуем графики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc3895f8>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxyiixo4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc08e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g, ax = plt.subplots(1,1)\n",
    "ax.plot(r_2['n_estimators'], r_2['score'], color='r')\n",
    "ax.plot(r_2['n_estimators'], r_2['Hold score'], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синяя кривая - оценка на валидации. Получим лучшее значение числа деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "      <th>Hold score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>750.0</td>\n",
       "      <td>0.793526</td>\n",
       "      <td>0.717678</td>\n",
       "      <td>0 days 00:00:29.114665000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators     score  Hold score                       time\n",
       "11         750.0  0.793526    0.717678  0 days 00:00:29.114665000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_2[r_2['Hold score']==r_2['Hold score'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "Ранее была получена модель (n_estimators=250, max_depth=3, learning_rate=0.2), которая давала точность на отложенной выборке = 0.720970.\n",
    "\n",
    "Точность последней модели (n_estimators=750, max_depth=3, learning_rate=0.1) = 0.717678\n",
    "\n",
    "Выглядит так, что имеет смысл продолжать первый подход, увеличивая там количество деревьев. Тем не менее, тут мы оставновимся.\n",
    "\n",
    "Обучим лучшие модели на полных данных и загрузим их на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=250, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[original_columns]\n",
    "\n",
    "# Модель 1\n",
    "clf_1 = GradientBoostingClassifier(n_estimators=250, learning_rate=0.2, max_depth=3)\n",
    "\n",
    "clf_1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76166551395321647"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf_1.predict_proba(X)\n",
    "train_score = roc_auc_score(y, y_train_pred[:,1])\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_result = clf_1.predict_proba(test[original_columns])[:,1]\n",
    "# Сохраним данные в формате kaggle\n",
    "predicted = DataFrame([])\n",
    "predicted['radiant_win'] = y_result\n",
    "predicted['match_id'] = test.index\n",
    "predicted = predicted.set_index('match_id')\n",
    "predicted.to_csv('./data/submission_1.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим вторую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=750, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель 2\n",
    "clf_2 = GradientBoostingClassifier(n_estimators=750, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "clf_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77763169487064054"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf_2.predict_proba(X)\n",
    "train_score = roc_auc_score(y, y_train_pred[:,1])\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_result = clf_2.predict_proba(test[original_columns])[:,1]\n",
    "# Сохраним данные в формате kaggle\n",
    "predicted = DataFrame([])\n",
    "predicted['radiant_win'] = y_result\n",
    "predicted['match_id'] = test.index\n",
    "predicted = predicted.set_index('match_id')\n",
    "predicted.to_csv('./data/submission_2.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на kaggle:\n",
    "\n",
    "Модель 1: 0.72726 (место 742 из 813)\n",
    "\n",
    "Модель 2: 0.73150 (место 736 из 813)\n",
    "\n",
    "Вот такой сюрприз.\n",
    "\n",
    "Очень высокая вероятность того, что если увеличить количество деревьев в первом подходе, результат будет лучше. Но с другой стороны очевидно, что борьба будет за доли процентов и без feature ingeneering не обойтись."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание победителя методом логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть кода повторяется, так как изначально это было 2 отдельных блокнота, но coursera позволяет загрузить лишь один блокнот. Поэтому был копи-паст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузим данные\n",
    "data = pd.read_csv('./data/features.csv', index_col='match_id')\n",
    "test = pd.read_csv('./data/features_test.csv', index_col='match_id')\n",
    "\n",
    "# Удалим столбцы из будущего и время начала матча\n",
    "data = data.drop(['start_time','duration',\n",
    "                  'tower_status_radiant', 'tower_status_dire', \n",
    "                  'barracks_status_radiant', 'barracks_status_dire'], axis=1)\n",
    "test = test.drop(['start_time'], axis=1)\n",
    "\n",
    "# По инструкции - заполним все NaN на 0\n",
    "data = data.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "# Отделим от тестового набора верные ответы\n",
    "y = data.pop('radiant_win')\n",
    "\n",
    "# Нормализуем все переменные\n",
    "scaler = StandardScaler()\n",
    "# Преобразуем обучающую выборку\n",
    "X = scaler.fit_transform(data)\n",
    "# Аналогично преобразуем тестовую выборку\n",
    "X_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "          C  KFold score  Hold score                       time\n",
      "1     0.001     0.717395    0.711821  0 days 00:00:09.898567000\n",
      "2     0.010     0.717417    0.711978  0 days 00:00:14.587834000\n",
      "3     0.100     0.717712    0.711921  0 days 00:00:15.635894000\n",
      "4     1.000     0.717796    0.711914  0 days 00:00:16.013916000\n",
      "5    10.000     0.717785    0.711913  0 days 00:00:16.135923000\n",
      "6   100.000     0.717696    0.711913  0 days 00:00:15.982915000\n",
      "7  1000.000     0.717704    0.711913  0 days 00:00:15.904910000\n",
      "\n",
      "Best KFold score:\n",
      "     C  KFold score  Hold score                       time\n",
      "4  1.0     0.717796    0.711914  0 days 00:00:16.013916000\n",
      "\n",
      "Best Hold score:\n",
      "      C  KFold score  Hold score                       time\n",
      "2  0.01     0.717417    0.711978  0 days 00:00:14.587834000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Далее проведем подбор параметра C. Поскольку код выполняется достаточно долго,\n",
    "# то мы сделаем это лишь один раз и сохраним результаты в файл.\n",
    "# Если нам в следующий раз потребуются результаты, то нет необходимости делать\n",
    "# вычисления снова - мы просто загрузим данные из файла.\n",
    "# Чтобы снова проделать вычисления - после if нужно поставить True\n",
    "if False:\n",
    "    # Разобьем выборку на обучающую и тестовую (30%). \n",
    "    # Это не является необходимым, просто для интереса.\n",
    "    X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Помимо валидации на отложенной выборке будем делать KFold, как и требуется по условию\n",
    "    cv = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    # i - обычный счетчик, r - DataFrame, куда мы будем записывать значения на итерациях\n",
    "    i = 1\n",
    "    r = DataFrame([])      \n",
    "    \n",
    "    # Сделаем список возможных С\n",
    "    C_list = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "    # combs_cnt - количество вариантов параметров\n",
    "    combs_cnt = len(C_list) \n",
    "\n",
    "    # По всем вариантам C строим классификатор и смотрим score    \n",
    "    for C in C_list:\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        # cross_val_score возвращает несколько значений, сразу возьмем среднее\n",
    "        score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv, scoring='roc_auc').mean()\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        # Поскольку мы делаем еще и валидацию на отложенной выборке, то \n",
    "        # обучим модель на тренировочном кусочке, сделаем прогноз для отложенной выборки\n",
    "        # и посчитаем score\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hold_pred = clf.predict_proba(X_hold)\n",
    "        on_hold_score = roc_auc_score(y_hold, y_hold_pred[:,1])\n",
    "        \n",
    "        # Запишем результаты итерации в DataFrame r\n",
    "        r.loc[i, 'C'] = C\n",
    "        r.loc[i, 'KFold score'] = score                \n",
    "        r.loc[i, 'Hold score'] = on_hold_score\n",
    "        r.loc[i, 'time'] = end_time-start_time\n",
    "             \n",
    "        # Распечатаем промежуточный результат шага, чтобы видеть прогресс\n",
    "        print('Step {}/{}:\\n{}\\n'.format(i, combs_cnt, r))\n",
    "        i += 1\n",
    "    # Сохраним результаты в файл, чтобы не пришлось делать вычисления снова        \n",
    "    r.to_csv('./data/logit_result_3.csv', index=True, header=True)        \n",
    "    print('FINISHED!\\n')  \n",
    "else:\n",
    "    # Этот блок выполняется, если мы не хотим снова делать расчеты, а хотим использовать сохраненные ранее\n",
    "    r = pd.read_csv('./data/logit_result_3.csv', index_col=0)\n",
    "    \n",
    "# Выведем таблицу с результатами\n",
    "print('Final results:\\n{}\\n'.format(r))\n",
    "print('Best KFold score:\\n{}\\n'.format(r[r['KFold score']==r['KFold score'].max()]))\n",
    "print('Best Hold score:\\n{}\\n'.format(r[r['Hold score']==r['Hold score'].max()]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc39ecf8>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc39e9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g, ax = plt.subplots(1,1)\n",
    "ax.plot(r['C'], r['KFold score'], color='r')\n",
    "#ax.plot(r['C'], r['Hold score'], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ни крути, но результат практически на зависит от C. Наверное, имеет смысл поставить C=1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели после удаления категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lobby_type', 'r1_hero', 'r1_level', 'r1_xp', 'r1_gold', 'r1_lh', 'r1_kills', 'r1_deaths',\n",
       "       'r1_items', 'r2_hero',\n",
       "       ...\n",
       "       'h_100', 'h_101', 'h_102', 'h_103', 'h_104', 'h_105', 'h_106', 'h_109', 'h_110', 'h_112'],\n",
       "      dtype='object', length=209)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраним на будущее старый набор полей\n",
    "original_columns = data.columns\n",
    "original_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создадим группы колонок с Героями, чтобы потом их можно было легко использовать в будущем\n",
    "r_heroes_cols = ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero']\n",
    "d_heroes_cols = ['d1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "\n",
    "# Колонки с героями обеих команд\n",
    "heroes_cols = r_heroes_cols + d_heroes_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_wo_categorial = [x for x in original_columns if x not in heroes_cols] #list() - ['lobby_type'] - list(heroes_cols)\n",
    "columns_wo_categorial.remove('lobby_type') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "          C  KFold score  Hold score                       time\n",
      "1     0.001     0.743119    0.745316  0 days 00:03:19.101388000\n",
      "2     0.010     0.750635    0.751204  0 days 00:04:58.436070000\n",
      "3     0.100     0.750902    0.751417  0 days 00:06:27.208148000\n",
      "4     1.000     0.751146    0.751369  0 days 00:06:26.733119000\n",
      "5    10.000     0.750808    0.751363  0 days 00:06:50.676490000\n",
      "6   100.000     0.750859    0.751390  0 days 00:06:13.154343000\n",
      "7  1000.000     0.751174    0.751376  0 days 00:07:37.945193000\n",
      "\n",
      "Best KFold score:\n",
      "        C  KFold score  Hold score                       time\n",
      "7  1000.0     0.751174    0.751376  0 days 00:07:37.945193000\n",
      "\n",
      "Best Hold score:\n",
      "     C  KFold score  Hold score                       time\n",
      "3  0.1     0.750902    0.751417  0 days 00:06:27.208148000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Далее проведем подбор параметра C. Поскольку код выполняется достаточно долго,\n",
    "# то мы сделаем это лишь один раз и сохраним результаты в файл.\n",
    "# Если нам в следующий раз потребуются результаты, то нет необходимости делать\n",
    "# вычисления снова - мы просто загрузим данные из файла.\n",
    "# Чтобы снова проделать вычисления - после if нужно поставить True\n",
    "X = data[columns_wo_categorial]\n",
    "\n",
    "if False:\n",
    "    # Разобьем выборку на обучающую и тестовую (30%). \n",
    "    # Это не является необходимым, просто для интереса.\n",
    "    X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Помимо валидации на отложенной выборке будем делать KFold, как и требуется по условию\n",
    "    cv = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    # i - обычный счетчик, r - DataFrame, куда мы будем записывать значения на итерациях\n",
    "    i = 1\n",
    "    r = DataFrame([])      \n",
    "    \n",
    "    # Сделаем список возможных С\n",
    "    C_list = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "    # combs_cnt - количество вариантов параметров\n",
    "    combs_cnt = len(C_list) \n",
    "\n",
    "    # По всем вариантам C строим классификатор и смотрим score    \n",
    "    for C in C_list:\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        # cross_val_score возвращает несколько значений, сразу возьмем среднее\n",
    "        score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv, scoring='roc_auc').mean()\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        # Поскольку мы делаем еще и валидацию на отложенной выборке, то \n",
    "        # обучим модель на тренировочном кусочке, сделаем прогноз для отложенной выборки\n",
    "        # и посчитаем score\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hold_pred = clf.predict_proba(X_hold)\n",
    "        on_hold_score = roc_auc_score(y_hold, y_hold_pred[:,1])\n",
    "        \n",
    "        # Запишем результаты итерации в DataFrame r\n",
    "        r.loc[i, 'C'] = C\n",
    "        r.loc[i, 'KFold score'] = score                \n",
    "        r.loc[i, 'Hold score'] = on_hold_score\n",
    "        r.loc[i, 'time'] = end_time-start_time\n",
    "             \n",
    "        # Распечатаем промежуточный результат шага, чтобы видеть прогресс\n",
    "        print('Step {}/{}:\\n{}\\n'.format(i, combs_cnt, r))\n",
    "        i += 1\n",
    "    # Сохраним результаты в файл, чтобы не пришлось делать вычисления снова        \n",
    "    r.to_csv('./data/logit_result_4.csv', index=True, header=True)        \n",
    "    print('FINISHED!\\n')  \n",
    "else:\n",
    "    # Этот блок выполняется, если мы не хотим снова делать расчеты, а хотим использовать сохраненные ранее\n",
    "    r = pd.read_csv('./data/logit_result_4.csv', index_col=0)\n",
    "    \n",
    "# Выведем таблицу с результатами\n",
    "print('Final results:\\n{}\\n'.format(r))\n",
    "print('Best KFold score:\\n{}\\n'.format(r[r['KFold score']==r['KFold score'].max()]))\n",
    "print('Best Hold score:\\n{}\\n'.format(r[r['Hold score']==r['Hold score'].max()]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: оставляем C=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь попробуем с мешком героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lobby_type', 'r1_hero', 'r1_level', 'r1_xp', 'r1_gold', 'r1_lh', 'r1_kills', 'r1_deaths',\n",
       "       'r1_items', 'r2_hero',\n",
       "       ...\n",
       "       'radiant_ward_sentry_count', 'radiant_first_ward_time', 'dire_bottle_time',\n",
       "       'dire_courier_time', 'dire_flying_courier_time', 'dire_tpscroll_count', 'dire_boots_count',\n",
       "       'dire_ward_observer_count', 'dire_ward_sentry_count', 'dire_first_ward_time'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique heroes: 108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Объединим все колонки с героями из тренировочных данных и из тестовых данных\n",
    "# Хотя маловероятно, что в тестовых данных есть герои, которые не использовались\n",
    "# в тренировочных, но все же сделаем это\n",
    "heroes = data[heroes_cols].append(test[heroes_cols])\n",
    "# Получим массив с уникальными id героев\n",
    "unique_heroes = np.unique(heroes.values)\n",
    "# Количество героев - это размерность массива\n",
    "print('Number of unique heroes: {}\\n'.format(unique_heroes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сформируем мешок из героев\n",
    "for i in unique_heroes:\n",
    "    # Сформируем название поля вида h_1, h_2 и т.д.\n",
    "    h_name = 'h_'+str(i)\n",
    "    # Выведем поле для оценки прогресса\n",
    "    # print(h_name)\n",
    "    # По всем столбцам с героями команды сделаем сравнение значения с id героя\n",
    "    # Если номер героя совпадет, то в результате будет True, иначе False\n",
    "    # Сделав сумму по всем таким полям каждой строчки мы получим 1, если\n",
    "    # есть True, или 0, если нет True\n",
    "    # Поскольку за игру герой может использоваться лишь 1 раз, то возможные значения {0, 1}\n",
    "    \n",
    "    # r - это столбец с 0 или 1 для данного героя в команде Radiant\n",
    "    r = (data[r_heroes_cols]==i).sum(axis=1)\n",
    "    # d - это аналогичный столбец с 0 или 1 для данного героя в команде Dire\n",
    "    d = (data[d_heroes_cols]==i).sum(axis=1)\n",
    "    # Разница между столбцами даст другой столбец с {-1,0,1}\n",
    "    # Этот столбец мы тут же добавляем в DataFrame data \n",
    "    data[h_name] = r - d\n",
    "    \n",
    "    # Аналогично сделаем для тестовой выборки\n",
    "    r = (test[r_heroes_cols]==i).sum(axis=1)\n",
    "    d = (test[d_heroes_cols]==i).sum(axis=1)\n",
    "    test[h_name] = r - d    \n",
    "\n",
    "bag_of_heroes_columns = [x for x in original_columns if x not in heroes_cols] #list() - ['lobby_type'] - list(heroes_cols)\n",
    "bag_of_heroes_columns.remove('lobby_type') \n",
    "#bag_of_heroes_columns\n",
    "\n",
    "# Удалим лобби и героев, так как они больше не нужны\n",
    "#data = data.drop(['lobby_type'] + heroes_cols, axis=1)                      \n",
    "#test = test.drop(['lobby_type'] + heroes_cols, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "          C  KFold score  Hold score                       time\n",
      "1     0.001     0.750663    0.749952  0 days 00:00:18.473057000\n",
      "2     0.010     0.751583    0.750714  0 days 00:00:26.353507000\n",
      "3     0.100     0.751545    0.750730  0 days 00:00:28.378623000\n",
      "4     1.000     0.751535    0.750731  0 days 00:00:29.962713000\n",
      "5    10.000     0.751264    0.750731  0 days 00:00:30.097722000\n",
      "6   100.000     0.751296    0.750731  0 days 00:00:28.754645000\n",
      "7  1000.000     0.751103    0.750731  0 days 00:00:28.817648000\n",
      "\n",
      "Best KFold score:\n",
      "      C  KFold score  Hold score                       time\n",
      "2  0.01     0.751583    0.750714  0 days 00:00:26.353507000\n",
      "\n",
      "Best Hold score:\n",
      "        C  KFold score  Hold score                       time\n",
      "7  1000.0     0.751103    0.750731  0 days 00:00:28.817648000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тут мы тупо скопируем код, который был выше. Можно сделать процедуру, но лень.\n",
    "# Никаких отличий в коде нет\n",
    "# Есть лишь отличие в данных, тут добавились поля с героями\n",
    "\n",
    "# Нормализуем все переменные\n",
    "scaler = StandardScaler()\n",
    "# Преобразуем обучающую выборку\n",
    "X = scaler.fit_transform(data[bag_of_heroes_columns])\n",
    "# Аналогично преобразуем тестовую выборку\n",
    "X_test = scaler.transform(test[bag_of_heroes_columns])\n",
    "\n",
    "# Про включение-выключение расчетов - см. аналогичный блок выше\n",
    "if False:\n",
    "    # Разобьем выборку на обучающую и тестовую (30%). \n",
    "    # Это не является необходимым, просто для интереса.\n",
    "    X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Помимо валидации на отложенной выборке будем делать KFold, как и требуется по условию\n",
    "    cv = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    # i - обычный счетчик, r - DataFrame, куда мы будем записывать значения на итерациях\n",
    "    i = 1\n",
    "    r = DataFrame([])      \n",
    "    \n",
    "    # Сделаем список возможных С\n",
    "    C_list = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "    # combs_cnt - количество вариантов параметров\n",
    "    combs_cnt = len(C_list) \n",
    "\n",
    "    # По всем вариантам C строим классификатор и смотрим score    \n",
    "    for C in C_list:\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        # cross_val_score возвращает несколько значений, сразу возьмем среднее\n",
    "        score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv, scoring='roc_auc').mean()\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        # Поскольку мы делаем еще и валидацию на отложенной выборке, то \n",
    "        # обучим модель на тренировочном кусочке, сделаем прогноз для отложенной выборки\n",
    "        # и посчитаем score\n",
    "        clf = LogisticRegression(C=C, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hold_pred = clf.predict_proba(X_hold)\n",
    "        on_hold_score = roc_auc_score(y_hold, y_hold_pred[:,1])\n",
    "        \n",
    "        # Запишем результаты итерации в DataFrame r\n",
    "        r.loc[i, 'C'] = C\n",
    "        r.loc[i, 'KFold score'] = score                \n",
    "        r.loc[i, 'Hold score'] = on_hold_score\n",
    "        r.loc[i, 'time'] = end_time-start_time\n",
    "             \n",
    "        # Распечатаем промежуточный результат шага, чтобы видеть прогресс\n",
    "        print('Step {}/{}:\\n{}\\n'.format(i, combs_cnt, r))\n",
    "        i += 1\n",
    "    # Сохраним результаты в файл, чтобы не пришлось делать вычисления снова        \n",
    "    r.to_csv('./data/logit_result_heroes.csv', index=True, header=True)        \n",
    "    print('FINISHED!\\n')  \n",
    "else:\n",
    "    # Этот блок выполняется, если мы не хотим снова делать расчеты, а хотим использовать сохраненные ранее\n",
    "    r = pd.read_csv('./data/logit_result_heroes.csv', index_col=0)\n",
    "    \n",
    "# Выведем таблицу с результатами\n",
    "print('Final results:\\n{}\\n'.format(r))\n",
    "print('Best KFold score:\\n{}\\n'.format(r[r['KFold score']==r['KFold score'].max()]))\n",
    "print('Best Hold score:\\n{}\\n'.format(r[r['Hold score']==r['Hold score'].max()])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка та же, результат не зависит от C. Возьмем С=1.0\n",
    "\n",
    "Однако точность улучшилась. Без мешка героев точность была 0.717796, с мешком 0.751535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Публикация данных на kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[original_columns]\n",
    "\n",
    "# Модель 1\n",
    "clf_1 = LogisticRegression(C=0.1, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "\n",
    "clf_1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71786583422142314"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf_1.predict_proba(X)\n",
    "train_score = roc_auc_score(y, y_train_pred[:,1])\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_result = clf_1.predict_proba(test[original_columns])[:,1]\n",
    "# Сохраним данные в формате kaggle\n",
    "predicted = DataFrame([])\n",
    "predicted['radiant_win'] = y_result\n",
    "predicted['match_id'] = test.index\n",
    "predicted = predicted.set_index('match_id')\n",
    "predicted.to_csv('./data/submission_3.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с мешком героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[bag_of_heroes_columns]\n",
    "\n",
    "# Модель 1\n",
    "clf_2 = LogisticRegression(C=0.1, max_iter=2000, penalty='l2', tol=0.00001)\n",
    "\n",
    "clf_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75428895557836473"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = clf_2.predict_proba(X)\n",
    "train_score = roc_auc_score(y, y_train_pred[:,1])\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_result = clf_2.predict_proba(test[bag_of_heroes_columns])[:,1]\n",
    "# Сохраним данные в формате kaggle\n",
    "predicted = DataFrame([])\n",
    "predicted['radiant_win'] = y_result\n",
    "predicted['match_id'] = test.index\n",
    "predicted = predicted.set_index('match_id')\n",
    "predicted.to_csv('./data/submission_4.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на kaggle:\n",
    "\n",
    "Модель 1: 0.72267 (место 757 из 813)\n",
    "\n",
    "Модель 2: 0.75489 (место 624 из 813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
